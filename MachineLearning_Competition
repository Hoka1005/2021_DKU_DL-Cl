# --------------------------------------
#
#   딥러닝 / 클라우드 머신러닝 경진대회
#
#   32153808 이호국
#
# --------------------------------------

import pandas as pd
import numpy as np
import pprint

from mlxtend.feature_selection import SequentialFeatureSelector as SFS
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import cross_val_score


# --------------------------------------
#
#   Initialze
#
# --------------------------------------


df = pd.read_csv('C:/data/train_open.csv')
df_X = df.iloc[:,0:22]
df_y = df.iloc[:,22]

pp = pprint.PrettyPrinter(width=80, indent=4)

model = LogisticRegression(solver='lbfgs', max_iter=3000)
model = RandomForestClassifier(random_state=1234)
model = SVC()


feature_num = 12
print("\nFeature Selection count : "+ str(feature_num)+"\n")
parll = 6

LR_grid = {
    'penalty' : ['l2', 'none'],
    'C': [1, 5, 10]
    }

RF_grid = {
    'n_estimators' :[50, 100, 500],
    'max_depth' :[None, 2, 4, 6, 8, 10],
    'criterion' :['gini', 'entropy'],
    'min_samples_leaf' : [1, 5, 10],
    'min_samples_split' : [2, 10, 20]
    }

RF_grid2 = {
    'criterion' :['gini', 'entropy'],
    'n_estimators' : [50, 100, 500, 1000],
    'max_depth' : [None, 2, 7, 9, 10, 15, 50],
    'max_samples' : [None, 0.1, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8]
    }

SVC_grid = {
    'kernel' : ['linear', 'rbf', 'sigmoid'],
    'C' : [0.1, 1, 10, 100],
    'gamma' : ['auto', 0.001, 0.01, 0.1, 1, 10]
    }


# --------------------------------------
#
#   Check Basic Model Accuracy
#
# --------------------------------------


scores = cross_val_score(model, df_X, df_y, cv=5, n_jobs = parll)
print("Basic Accuracy : "+str(scores.mean())+'\n')


# --------------------------------------
#
#   Filter Method
#
# --------------------------------------


test = SelectKBest(score_func=chi2, k=df_X.shape[1])
fit = test.fit(df_X, df_y)

print(np.round(fit.scores_, 3))
f_order = np.argsort(-fit.scores_)
sorted_columns = df.columns[f_order]

print("Filter Method Test\n")
print(sorted_columns.tolist())
print()

filtered_columns = sorted_columns[0:11]
df_X = pd.DataFrame(df_X, columns=filtered_columns)


#---------------------------------------
#
#   Forward Selection
#
# --------------------------------------


sfs1 = SFS(model,
           k_features= feature_num,
           scoring = 'accuracy', 
           cv = 5, 
           forward=True,
           n_jobs = parll)

sfs1 = sfs1.fit(df_X, df_y)
sfs1.subsets_
sfs1.k_feature_names_
df_X2 = pd.DataFrame(df_X, columns = sfs1.k_feature_names_)
print("Forward Selection Complete\n")


# --------------------------------------
#
#   Backward Elimination
#
# --------------------------------------

sfs2 = SFS(model,
           k_features= feature_num,
           scoring = 'accuracy', 
           cv = 5, 
           forward=False,
           n_jobs = parll)

sfs2 = sfs2.fit(df_X, df_y)
sfs2.subsets_
sfs2.k_feature_names_
df_X3 = pd.DataFrame(df_X, columns = sfs2.k_feature_names_)
print("Backward Elimination Complete\n")


# --------------------------------------
#
#   Find best parameter using GridSearchCV
#
# --------------------------------------

grid_search = GridSearchCV(estimator = model, param_grid = LR_grid, cv=5, verbose=1, n_jobs=parll)
grid_search = GridSearchCV(estimator = model, param_grid = RF_grid, cv=5, verbose=1, n_jobs=parll)
grid_search = GridSearchCV(estimator = model, param_grid = SVC_grid, cv=5, verbose=1, n_jobs=parll)


print("Forward Selection")
grid_search.fit(df_X2, df_y)
pp.pprint(grid_search.best_params_)

best_model_f = grid_search.best_estimator_
best_accuracy_f = best_model_f.score(df_X2, df_y)
print('FS - Best Accuracy: ' + str(best_accuracy_f))


print("Backward Elimination")
grid_search.fit(df_X3, df_y)
pp.pprint(grid_search.best_params_)

best_model_b = grid_search.best_estimator_
best_accuracy_b = best_model_b.score(df_X3, df_y)
print('BE - Best Accuracy: ' + str(best_accuracy_b))


# --------------------------------------
#
#   Feature Selection & Predict in test data
#
# --------------------------------------


test_set = pd.read_csv('C:/data/test_open.csv')
test_set = pd.DataFrame(test_set, columns = sfs2.k_feature_names_)
result = best_model_b.predict(test_set)


# --------------------------------------
#
#   Write result as CSV
#
# --------------------------------------


pd.DataFrame(result).to_csv('C:/data/32153808_이호국.csv', sep=',', index=False)

